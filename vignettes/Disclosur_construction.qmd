---
title: "Disclosur_Construction"
author: "Chris Cioffi"
format: html
editor: visual
---

```{r}
# set libraries
library("httr2")
library("tidyverse")
library("keyring")
```

# DisclosuR

#### The experimentation with a query of fedferal lobbying disclosures that we hope will one day become an R package

# get_filings()

#### This is the function that we'll make the heart of our package - an example query is below the function

-   Users can search for specific issues using 'what_issue = list(c("item", "item", "item"), "and/or"),' and use "and" or "or" to link certain terms or just search for some of those terms.

-   Users can search for specific filing periods using the 'what_filing_period = "first_quarter/second_quarter/third_quarter/fourth_quarter"' - this returns not only the quarterly filings but new registrations, amendments or terminations as well.

-   Specific clients and registrants can also be sought using the 'what_client_name = "entity"', and what_registrant_name = "entity" entries.

-   Specific dates can also be snagged using the 'ending_when = "YYYY-MM-DD"' and\
    'starting_when = "YYYY-MM-DD"'

-   I've created a basic helper to try and get rid of a bunch of other columns that come up in the result and you can do that too using the 'tidy_result = TRUE'. **But** I encourage you to look at some of the fill in-in-the-blank forms that lobbyists fill out (available in the non-tidy view) that may help you find other lobbying topics and similar words being used.

-   There's also a lengthy disclaimer that I threw in there, so once you read it you can add in 'ignore_disclaimer = FALSE' so you don't have to read it a bunch of times.

```{r}
get_filings <- function(what_issue = list(c(""), ""),
                        what_year = "",
                        what_filing_period = "",
                        what_client_name = "",
                        what_registrant_name = "",
                        starting_when = "",
                        ending_when = "",
                        tidy_result = TRUE,
                        ignore_disclaimer = FALSE) {
  ######### take specific issues and combine it in a proper format to ping the API
  specific_issues <- function(lobbying_issues = "", join_word = "") { ### corrected
    # Wrap each term in double quotes
    terms <- paste0('"', lobbying_issues, '"')
    # Define the join string
    joiner <- switch(tolower(join_word),
      "and" = "+AND+", # if the user supplies and which returns disclosures with all terms
      "or"  = "OR", # if the user supplies or which returns disclosures with any terms (Note no + sign in this function)
      join_word # fallback
    )
    # Combine terms and handle empty case
    query_string <- if (length(terms) > 0 && nchar(terms[1]) > 0) {
      paste0(terms, collapse = joiner)
    } else {
      ""
    }

    # Add single quotes and check for empty quoted string
    query_string <- paste0("'", query_string, "'")
    if (query_string == "'\"\"'") query_string <- ""

    return(query_string)
  }
  # generate the issues we'll use in the next step

  several_issues <- specific_issues(what_issue[[1]], what_issue[[2]])

  # provide the base and filings urls
  base_url <- "https://lda.senate.gov"
  filings <- "/api/v1/filings/"

  # build the request based on what is provided
  req <- request(base_url) |>
    req_url_path(filings) |>
    req_headers(Authorization = paste0("Token ", keyring::key_get("senate_api_key"))) |>
    req_url_query(
      filing_specific_lobbying_issues = several_issues,
      filing_year = what_year,
      registrant_name = what_registrant_name,
      filing_period = what_filing_period, # what filing period are we searching for?
      client_name = what_client_name, # which client lobbyists are lobbying on behalf of are we looking for
      filing_dt_posted_before = ending_when, # the end date we're searching for
      filing_dt_posted_after = starting_when # the start date we're searching for
    ) |>
    req_throttle(rate = 120 / 60)


  resps <- req_perform_iterative(
    req |> req_url_query(page_size = 25),
    next_req = iterate_with_offset(
      "page",
      start = 1, # start at the first page
      offset = 1, # go up by one page each time
      resp_pages = function(resp) ceiling(resp_body_json(resp)$count / 25) # takes resp and returns the total number of pages, or NULL if unknown. It will only be called once.
    ),
    max_reqs = Inf
  )
  # save the result in case we want to use it again later
  write_rds(resps, "resps_request_result.rds")

  # simple function to unpack each api result and bring to level of the responses

  unpackedhopeitworks <- resps |>
    resps_successes() |>
    resps_data(function(resp) resp_body_json(resp, check_type = TRUE, simplifyVector = TRUE, flatten = TRUE)$results) # flatten and simplify vector doing big lifts here to turn this into a df

  ### added later to expand the data to bring up each lobbying area and what the filer said about the issues they lobbied on in a given lobbying area to make it easier to potentially seek like terms and maybe fuzzy match at some point areas of interest ###

  data_to_work_with <- unpackedhopeitworks |>
    hoist(
      lobbying_activities,
      general_issue_code_display = "general_issue_code_display",
      description = "description"
    ) %>%
    unnest(c(general_issue_code_display, description), keep_empty = TRUE) |>
    group_by(registrant.name, client.name) |>
    pivot_wider(
      names_from = general_issue_code_display,
      values_from = description,
      values_fn = list
    )

  # added as a cleaning function see wrangle data ctd section - basically just reducing the large multi-column response with the raw filing data to a very minimal format

  cleaner_view <- function(dataframe_i_want_to_use, tidy_up_response = TRUE) {
    if (tidy_up_response == TRUE) {
      dataframe_i_want_to_use |>
        select(any_of(c("registrant.name", "client.name", "filing_type_display", "income", "expenses", "filing_year", "dt_posted", "filing_document_url", "registrant.description", "client.general_description", "filing_type", "filing_period")))
    } else {
      return(dataframe_i_want_to_use)
    }
  }

  # return the tidied dataframe
  cleaned_data_to_work_with <- cleaner_view(data_to_work_with, tidy_up_response = tidy_result)


  # Print disclaimer at the end - this can be muted with mute messages -
  ignore_message <- function(mute_message = FALSE) {
    if (mute_message == FALSE) {
      message("DISCLAIMER: This data is known to contain errors and requires additional filtering and cleaning to ensure correct results.")
      message("See documentation for more guidance and filtering examples.")
      message()
      message("FACT CHECKING:")
      message("+If you're looking to fact-check, use the filing document url to look at the source of the information as it was filed.")
      message("+Ensure that there is only one filing for a given registrant in each filing_period for each year to avoid double counting the amount spent or earned on lobbying.")
      message()
      message("DOUBLE COUNTING:")
      message("If, for example, in the same quarter of a year an entity has a filing called '1st Quarter - Report', '1st Quarter - Termination' and '1st Quarter - Amendment', you must make sure to only count one of those (the latest is usually the most accurate) otherwise you risk double counting.")
      message("+The helper column called, 'double count risk' should have insights into some of these instances, but it's not perfect. So, double check.")
      message("+Registrations and terminations are separate from quarterly lobby spending and must be filtered out to determine an entity's yearly spending on lobbying.")
      message()
      message("MORE HELPFUL HINTS:")
      message("+If an entity name appears as a registrant, but also appears as a client. Do not sum the values. Instead, use the value in the registrant's expenses field to gauge the amount spent on lobbying by the registrant.")
      message()
      message("SOURCE: Federal lobbying disclosures maintained in the U.S. Senate Lobbying Disclosure Act Database and queried through the official Lobbying Disclosure REST API v1 - Read more here - https://lda.senate.gov/api/redoc/v1/")
    } else {
      message("Disclaimer is muted. But you should read it, and can do that by removing ignore_disclaimer = TRUE from DisclosuR call")
    }
  }

  # ignore the message if the disclaimer ignore option is set to true
  ignore_message(mute_message = ignore_disclaimer)

  # return the finished data from API
  return(cleaned_data_to_work_with)
}
```

## All options for running the function

Along with some sample ideas to make it work I note out lines when I don't want to use those pieces of the query

```{r}
bigger_temp <- get_filings(
  what_issue = list(c("tax", "trade", "company"), "and"),
  #what_year = 2024, # can be used for only one year at a time
  what_filing_period = "first_quarter",
 # what_client_name = "Chamber of Commerce of the U.S.A.",
#  what_registrant_name = "Chamber of Commerce of the U.S.A.",
  ending_when = "2025-1-25", # format yyyy-mm-dd
  starting_when = "2024-04-01", # format yyyy-mm-dd
  tidy_result = T,
  ignore_disclaimer = T
)
```

# flag_dupes()

#### flagging results that might be of-concern

I've created some columns that hopefully will help give you some hints on what might not be right about this data, and then, looking closer into those rows of concern and trying to choose which one to select.

The flag_dupes() function takes a df pulled from get_filings(), and has two options:

-   'find_duplicates =TRUE' which throws up a warning for users when dubious filings are encountered

-   'attempt_cleaning = TRUE' which takes the flagged duplicates and then removes all filings from that quarter, except the one filed last. The assumption I'm making here is that the last one is the most correct.

I would recommend digging in and doing some more careful analysis if you want to use it in a story.

```{r}
# got a bit of help creating the regexes and putting some of these together from perplexity ai

flag_dupes <- function(cleaned_dataframe_from_previous_function, find_duplicates = TRUE, attempt_cleaning = TRUE) {
  if (find_duplicates) {
    dupes_flagged <- cleaned_dataframe_from_previous_function |>
      mutate(
        registration_or_termination = str_detect(filing_type, regex("RR$|T$", ignore_case = TRUE)),
        quarter_number = str_extract(filing_type, "\\d+") |> as.integer(),
        is_amendment = str_detect(filing_type, "\\d+A$")
      ) |>
      group_by(registrant.name, client.name, filing_year, quarter_number) |>
      mutate(
        has_quarter = any(!is_amendment & !is.na(quarter_number)), # make sure we're flagging registrations by eliminating na and those that are not amendments
        has_amendment = any(is_amendment),
        registration_termination = any(registration_or_termination), # if the filling is a termination or a registration it would be easier to exclude them or carefully check them for accuracy
        is_duplicate = (duplicated(income) | duplicated(income, fromLast = TRUE) | duplicated(expenses) | duplicated(expenses, fromLast = TRUE)), # if the income or expenses column is duplicated, this could suggest there are two identical filings in a given quarter
        checkme = if_else(has_quarter & has_amendment, "CHECK", if_else(!has_quarter & !has_amendment & !is_amendment, "CHECK", if_else(registration_termination | is_amendment | is_duplicate, "CHECK", "PASS CHECK")))
      ) |>
      ungroup()
  } else {
    dupes_flagged <- cleaned_dataframe_from_previous_function
  }

  # Clean attempt function moved outside nested logic
  clean_attempt <- function(dataframe_with_flagged_dupes) {
    dataframe_with_flagged_dupes |>
      filter(!registration_or_termination) |>
      mutate(dt_posted = as.POSIXct(dt_posted)) |>
      group_by(registrant.name, client.name, filing_year, filing_period) |>
      arrange(desc(dt_posted)) |>
      slice_tail(n = 1) |> #select the last result (in this case, the latest filing which is typically the amended version)
      ungroup()
  }

  if (attempt_cleaning) {
    cleaned_and_flagged_dataframe <- clean_attempt(dupes_flagged)
  } else {
    cleaned_and_flagged_dataframe <- dupes_flagged
  }
  message("This function either removed or identified lobbying filings that, if left in, could lead to doublecounting of spending on lobbying. It is not perfect. Please see documentation on tips for fact-checking these by hand.")
  return(cleaned_and_flagged_dataframe)
}
```

#### Example query of flag_dupes()

```{r}
dupes_flag_test <- flag_dupes(bigger_temp, find_duplicates = TRUE, attempt_cleaning = T)
```

# flag_client_registrant_conflict()

This function seeks to flag instances where an entity filed as a registrant, which if the entity followed the rules, the expenses number should encompass all spending by that entity. If the registrant sought outside counsel, and those lobbyists filed their own documentation, they should have reported the income earned from the registrant in their filings. That allows us to say XX company spent \$XX to XX lobbyist to lobby on their behalf on XX issues. But, if a registrant filed their own documentation that lobbyist-reported income should already be included in the registrant's expenses total.

It's important not have both the registrant contribution and the lobbyist income in data, because we don't want to accidentally double count how much a registrant spent on lobbying.

In an effort to automate some of this process flag_client_registrant_conflict tries to flag some of these conflicts automatically.

The function takes a df pulled from get_filings() has two options:

-   'flag_conflict = TRUE' which creates a new column that identifies the filings that are likely duplicates as described above.

-   'clean_doublecounts = TRUE' which goes ahead and filters out those cases automatically.

Again, there's no guarantees it gets them all, so make sure to go through these by hand if you want to be absolutely sure the data is accurate.

```{r}
flag_client_registrant_conflict <- function(dataframe_that_i_determine, flag_conflict = TRUE, clean_doublecounts = TRUE) {
  if (flag_conflict) {
    # 1. Identify self-lobbying entities (registrant = client)
    self_lobbying_entities <- dataframe_that_i_determine |>
      filter(registrant.name == client.name) |>
      distinct(entity = registrant.name) # find distinct entities that report all lobbying in one report

    # 2. Find cross-lobbying cases (same entity as client with different registrant)
    cross_lobbying_cases <- dataframe_that_i_determine |>
      filter(client.name %in% self_lobbying_entities$entity) |>
      anti_join(self_lobbying_entities, by = c("registrant.name" = "entity"))

    # 3. Flag both cases in original data
    flagged_cases <- dataframe_that_i_determine |>
      mutate(
        flag = case_when(
          registrant.name == client.name ~ "Report of all entity's spending",
          client.name %in% self_lobbying_entities$entity ~ "Likely part of separate entity's report",
          TRUE ~ "No entity's report detected"
        )
      )
  } else {
    flagged_cases <- return(dataframe_that_i_determine)
  }
  # second function that filters out the rows part of the entity's report
  remove_client_registrant_conflict <- function(dataframe_i_cleaned_above) {
    no_client_registrant_conflict <- dataframe_i_cleaned_above |>
      filter(flag != "Likely part of separate entity's report")
  }

  if (clean_doublecounts) {
    filtered_dataframe_with_flagged_conflict_col <- remove_client_registrant_conflict(flagged_cases)
  } else {
    filtered_dataframe_with_flagged_conflict_col <- return(flagged_cases)
  }
  return(filtered_dataframe_with_flagged_conflict_col)
  message("This function either removed or identified lobbying filings that, if left in, could lead to doublecounting of spending on lobbying. It is not perfect. Please see documentation on tips for fact-checking these by hand.")
}
```

#### Example use of flag_client_registrant_conflict()

```{r}
flagged_conflict <- flag_client_registrant_conflict(bigger_temp, flag_conflict = TRUE, clean_doublecounts = TRUE)
```

# set_senate_api_key()

This is the function I created to save our API keys

It uses keyring. It takes no arguments.

All you have to do, is call it and it will prompt you to enter your api key. It stores it with the correct name to use it in the get_filings() function. 

```{r}
# enter api key when password request appears
set_senate_api_key <- function(api_key) {
  message("enter api key when password request appears")
  message("API keys can be requested here https://lda.senate.gov/api/register/")
  message("Pausing for 5 seconds so you can read...")
  Sys.sleep(5) # Pause for 3 seconds
  message("Ok, now you can enter your api key")
  key_set("senate_api_key")
}
```

#### Example use of set_senate_api_key()

```{r}
set_senate_api_key()
```

### to-do list of things to puzzle through -

-completed - use unpack or something hoist maybe to pull out that issue code and description

-completed - create a function that produces super clean few rows vs the entire api result

-completed - make the function in a way that mimics the way data gets cleaned in sheets

-completed - add into function to either query for quarterly filings or make it clear that registrations and quarterly filings should be separated in analysis

-completed - create a function that will attempt to "clean data, or at least generate a new column that will give some folks a head's up to flag if there might be double counting

-completed - did so in disclaimer - will also address in documentation - differentiate 12. Lobbying vs 13. Organizations (contributions vs income)

-completed -how do you flag dupes?

-best practices document for cleaning the data

list of things to troubleshoot

Not sure this is an issue or not but just want to flag for now when querying '"tires"OR"oecd"' I get four docs - client is michelin in all 4 but two have registrant name of the lobbyist Holly Strategies Incorporated (just a defense filing) and two are michelin's full disclosure

> testresp\[\["results"\]\]\[\[3\]\]\[\["filing_document_url"\]\] \[1\] "https://lda.senate.gov/filings/public/filing/a3536f7e-8b98-4ade-81a5-abade688e4c2/print/" testresp\[\["results"\]\]\[\[1\]\]\[\["filing_document_url"\]\] \[1\] "https://lda.senate.gov/filings/public/filing/ace5a086-5492-46af-93a6-6fe2f41cea7c/print/" testresp\[\["results"\]\]\[\[2\]\]\[\["filing_document_url"\]\] \[1\] "https://lda.senate.gov/filings/public/filing/41eed249-4eef-4b0f-95d4-0cc782a38f60/print/" testresp\[\["results"\]\]\[\[4\]\]\[\["filing_document_url"\]\] \[1\] "https://lda.senate.gov/filings/public/filing/3db71737-04aa-4eee-9211-22265ca8d8e3/print/"

but if you run '"tires"+AND+"oecd"' you just get the two michelin filings

# All other notes and noodling below

notes for me We received a password reset request for your Lobbying Disclosure REST API Key (Username: CHRISJCIOFFI).

Use this link and the UID and Token below to create your new password: https://lda.senate.gov/api/auth/password/reset/confirm/.

UID: MTQ2Mg Token: c3ip6w-9fbfff310bbdc9e2ab67d771f7351d33 pw: chris_cioffi_Disclosures API_Key: "6afec64f3f0f06314fda06658b34efda889cc938"

```{r}
library("httr2")
library("tidyverse")
library("magrittr")
library("tidyjson")
library("keyring")
library("data.table")
library("jsonlite")

# set api key -
# key_set("senate_api_key")

# Set API key
# api_key <- "6afec64f3f0f06314fda06658b34efda889cc938"
```

#### STEP 1. Create lobbying Disclosure Query \@ \@ \@

This is the codeblock where we've created that will get you ready to make several requests below that will query the senate disclosures API

```{r}
base_url <- "https://lda.senate.gov"


# some of the node urls
lobbyists <- "/api/v1/lobbyists/"
contribs <- "/api/v1/contributions/"
filings <- "/api/v1/filings/" # this is what we're focused on
```

Note-- because the code in the next three blocks that provide the information for constructing API calls all use "req" so the subsequent blocks will function without being changed, make sure you're clearing out the environment when shifting between querying the API for Lobbyists versus Contributions versus Reports --

#### Test for Constructing API Call

2 - saving this because it's the block to construct a simplified version of an API call that I used as a jumping off point and came back to for as a jumping point

```{r}
# set up your request here

req <- request(base_url) |>
  req_url_path(filings) |>
  req_headers(Authorization = paste0("Token ", keyring::key_get("senate_api_key"))) |>
  req_url_query(filing_specific_lobbying_issues = "OECD", filing_year = 2024) |> # build query fields
  req_throttle(rate = 120 / 60)

# perform your request here and snag the first page so we can build URLS for ease of retrieval
resp <- req |>
  req_perform() |>
  resp_body_json()
```

#### Run test API Call

This section is where we're running the actual query for the given request we've formulated above.

```{r}
# see what httr2 is sending to server with this function
req_dry_run(req)

# perform the request

resps <- req_perform_iterative(
  req |> req_url_query(page_size = 25),
  next_req = iterate_with_offset(
    "page",
    start = 1, # start at the first page
    offset = 1, # go up by one page each time
    resp_pages = function(resp) ceiling(resp_body_json(resp)$count / 25) # takes resp and returns the total number of pages, or NULL if unknown. It will only be called once.
  ),
  max_reqs = Inf
)

# simple function to unpack each api result and bring to level of the responses - then turn the whole thing into a dataframe (simplifyvector=true) - we can figure out how we want to wrangle all the nested dfs (flatten = true) later
unpackedhopeitworks <- resps |>
  resps_successes() |>
  resps_data(function(resp) resp_body_json(resp, check_type = TRUE, simplifyVector = TRUE, Flatten = TRUE)$results)
```

#### Baby's first function

Once we've got a basic understanding of how the API works, let's turn it into a big function

```{r}
small_get_filings <- function(what_issue, what_year) {
  base_url <- "https://lda.senate.gov"
  filings <- "/api/v1/filings/"

  req <- request(base_url) |>
    req_url_path(filings) |>
    req_headers(Authorization = paste0("Token ", keyring::key_get("senate_api_key"))) |>
    req_url_query(
      filing_specific_lobbying_issues = what_issue,
      filing_year = what_year
    ) |>
    req_throttle(rate = 120 / 60)

  resps <- req_perform_iterative(
    req |> req_url_query(page_size = 25),
    next_req = iterate_with_offset(
      "page",
      start = 1, # start at the first page
      offset = 1, # go up by one page each time
      resp_pages = function(resp) ceiling(resp_body_json(resp)$count / 25) # takes resp and returns the total number of pages, or NULL if unknown. It will only be called once.
    ),
    max_reqs = Inf
  )
  # save the result in case we want to use it again later
  write_rds(resps, "resps_request_result.rds")

  # simple function to unpack each api result and bring to level of the responses
  unpackedhopeitworks <- resps |>
    resps_successes() |>
    resps_data(function(resp) resp_body_json(resp, check_type = TRUE, simplifyVector = TRUE, flatten = TRUE)$results)
  return(unpackedhopeitworks)
}
```

#### step 4.5 - now that we've got our function, let's run it

```{r}
# run function with basic searchterms
temp <- get_filings(what_issue = '"45x"+AND+"45z"', what_year = 2025)
temp <- get_filings(what_issue = '"45x"OR"45z"', what_year = 2025)
```

##### Add more query fields

now that we have structured data where each row corresponds to one result, even though those rows are a brutal tangle of nested lists(we can make that work better later) Let's experiment with more ways to query

+filing_period - filing_period any Enum: "first_quarter" "second_quarter" "third_quarter" "fourth_quarter" "mid_year" "year_end"

+client_name - string

\+ multiple search keywords

\+ the date you want to start your searchfiling_dt_posted_after string <date-time> Filing Date Posted Range (Before / After): yyyy-mm-dd -

\+ filing_dt_posted_before string <date-time> Filing Date Posted Range (Before / After): yyyy-mm-dd

\+ filing_specific_lobbying_issues - string - Filing Specific Lobbying Issues (Supports Advanced Text Searching)

\+ lobbyist_name - string Lobbyist Name

```{r}
######## start function ########
# function(lobbying_issues, join_word){
# terms <- c(lobbying_issues)
# query_string <- paste0( '"', terms, '"', collapse = function(or_and){
#   if join_word = "and", "+AND+",
#   if join_word = "or","OR"
#   else join_word = "")
#   }
# }
# thanks to chatGPT for helping put me on the right path with this one
# if user supplies no search terms or join words, the space is left blank

# we'll for sure need to throw some errors if it's bot working, like hey supply a valid join word or you put in 2 terms but no join word

specific_issues <- function(lobbying_issues = "", join_word = "") {
  # Wrap each term in double quotes
  terms <- paste0('"', lobbying_issues, '"')
  # Define the join string
  joiner <- switch(tolower(join_word),
    "and" = "+AND+", # if the user supplies and which returns disclosures with all terms
    "or"  = "OR", # if the user supplies or which returns disclosures with any terms
    join_word # fallback
  )

  # Combine the quoted terms with the joiner
  query_string <- paste0(terms, collapse = joiner)
  query_string <- paste0("'", query_string, "'")
  return(query_string)
}

############ end of function #############

# write all search terms you want to find here, and then supply whether you want to find all terms or just any terms
many_issues <- (list(c("45z", "45x"), "or"))
string_keywords <- specific_issues(many_issues[[1]], many_issues[[2]])




# create that request
req <- request(base_url) |>
  req_url_path(filings) |>
  req_headers(Authorization = paste0("Token ", keyring::key_get("senate_api_key"))) |>
  req_url_query(
    filing_specific_lobbying_issues = '"tire"OR"oecd"', # the issues you want to search for -this got tricky because the convention is like this (Note no + sign in this function) filing_specific_lobbying_issues=%22OECD%22+AND+%22tire%22
    filing_year = "2024", # what filing year are we interested in?
    filing_period = "first_quarter", # what filing period are we searching for?
    client_name = "MICHELIN NORTH AMERICA, INC.", # the name of the client we're searching
    filing_dt_posted_before = "2024-05-23", # the end date we're searching for
    filing_dt_posted_after = "2024-01-01" # the start date we're searching for
  ) |>
  req_throttle(rate = 120 / 60)

# test it to see if we're gonna get anywhere with it
testresp <- req |>
  req_perform() |>
  resp_body_json()
```

#### wrangle data

So now that we have our function working ok, I'd like to accomplish a few things â€” that makes the data our function returns easier to read that removes some of the less useful rows

What I did below is to pull the issues the companies lobbied on and their descriptions into a column so it's easier to understand in the aggregate.

This was then added into the above function

```{r}
# subset rows if I want to do easier analysis - utilized perplexity AI to help do this and organize it.
data_to_work_with <- analysis_temp |>
  hoist(
    lobbying_activities,
    general_issue_code_display = "general_issue_code_display",
    description = "description"
  ) %>%
  unnest(c(general_issue_code_display, description), keep_empty = TRUE) |>
  group_by(registrant.name, client.name) |>
  pivot_wider(
    names_from = general_issue_code_display,
    values_from = description,
    values_fn = list
  )

# little fact-checking checking here - both the api call and the data_to_work_with both have the same number of rows (127) when grouped by registrant and client -
# That also matches the identical query done through the LDA's GUI  https://lda.senate.gov/filings/public/filing/search/?registrant=&registrant_country=&registrant_ppb_country=&client=&client_state=&client_country=&client_ppb_country=&lobbyist=&lobbyist_covered_position=&lobbyist_conviction_disclosure=&lobbyist_conviction_date_range_from=&lobbyist_conviction_date_range_to=&report_type=Q1&report_period=first_quarter&report_year=2025&report_dt_posted_from=&report_dt_posted_to=&report_amount_reported_min=&report_amount_reported_max=&report_filing_uuid=&report_house_doc_id=&report_issue_area_description=%2245z%22+or+%2245x%22&affiliated_organization=&affiliated_organization_country=&foreign_entity=&foreign_entity_country=&foreign_entity_ppb_country=&foreign_entity_ownership_percentage_min=&foreign_entity_ownership_percentage_max=&search=search#js_searchFormTitle

analysis_temp |>
  filter(filing_type_display == "1st Quarter - Report") |>
  group_by(registrant.name, client.name) |>
  count()

data_to_work_with |>
  filter(filing_type_display == "1st Quarter - Report") |>
  group_by(registrant.name, client.name) |>
  count()
```

#### wrangle data ctd

Also want to add in some functionality that returns a much esier to use dataframe that only has what we need for analysis here

this was also added into the above function titled get_filings

EDIT - I opted to go with a simpler version of this that just returns high-level information but am leaving this here for later - I may create a second level of filtering at some point that allows for displaying search terms, but gets rid of less relevant items.

```{r}
# let's create a feature that will simplify this frame by discarding some columns that aren't necessary

cleaner_view <- function(dataframe_i_want_to_use, tidy_up_response = TRUE) {
  if (tidy_up_response == TRUE) {
    dataframe_i_want_to_use |>
      select(-any_of(c("url", "filing_period", "filing_uuid", "filing_document_content_type", "expenses_method", "expenses_method_display", "posted_by_name", "termination_date", "registrant_country", "registrant_ppb_country", "registrant_address_1", "registrant_address_2", "registrant_different_address", "lobbying_activities", "conviction_disclosures", "foreign_entities", "affiliated_organizations", "registrant.house_registrant_id", "registrant.address_1", "registrant.address_2", "registrant.address_3", "registrant.address_4", "registrant.city", "registrant.state", "registrant.state_display", "registrant.zip", "registrant.country", "registrant.country_display", "registrant.ppb_country", "registrant.ppb_country_display", "registrant_city", "registrant.contact_name", "registrant.contact_telephone", "registrant.dt_updated", "client.client_id", "client.state_display", "client.effective_date", "filing_period_display", "registrant.id", "registrant_zip", "client.client_government_entity", "client.client_self_select", "client.country_display", "client.country", "client.ppb_state", "client.ppb_country", "client.ppb_state_display", "client.ppb_country_display"))) |>
      relocate(c("registrant.name", "client.name", "filing_type_display", "income", "expenses", "filing_year", "dt_posted", "filing_type"))
  } else {
    return(dataframe_i_want_to_use)
  }
}

temp <- cleaner_view(data_to_work_with, tidy_up_response = TRUE)
```
